{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost\n",
    "import graphviz\n",
    "\n",
    "RANDOM_SEED = 1212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/small/train/orange_small_train.data', sep=\"\\t\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_label = (\n",
    "    pd.read_csv(\n",
    "        \"../data/small/labels/orange_small_train_churn.labels\", sep=\"\\t\", header=None\n",
    "    )\n",
    "    .iloc[:, 0]\n",
    "    .astype(\"category\")\n",
    ")\n",
    "\n",
    "churn_label.cat.rename_categories([False, True], inplace=True)\n",
    "\n",
    "churn_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe(DF):\n",
    "    df_var_names = DF.columns\n",
    "\n",
    "    df_types = {df_var_name: DF[df_var_name].dtype for df_var_name in df_var_names}\n",
    "\n",
    "    for df_var_name in df_var_names:\n",
    "        if df_types[df_var_name] == int:\n",
    "            df = DF[df_var_name].astype(float)\n",
    "            DF.loc[:, df_var_name] = df\n",
    "            df_types[df_var_name] = df.dtype\n",
    "\n",
    "        elif df_types[df_var_name] != float:\n",
    "            df = DF[df_var_name].astype(\"category\")\n",
    "            DF.loc[:, df_var_name] = df\n",
    "            df_types[df_var_name] = df.dtype\n",
    "\n",
    "    return DF, df_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_types = convert_dataframe(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    train, churn_label, test_size=0.2, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_data(x_train, x_test):\n",
    "    x_train_missing = x_train.isnull().sum() / x_train.shape[0]\n",
    "    x_test_missing = x_test.isnull().sum() / x_test.shape[0]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), sharex=\"all\", sharey=\"all\")\n",
    "    ax1.hist(x_train_missing)\n",
    "    ax1.set_title(\"Train data\")\n",
    "    ax2.hist(x_test_missing)\n",
    "    ax2.set_title(\"Test data\")\n",
    "\n",
    "    fig.suptitle(\"Missing data proportions\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_data(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll consider valid only features that have less than 15% missing data of its total data as our model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_missing = x_train.isnull().sum() / x_train.shape[0]\n",
    "x_features = x_train_missing[x_train_missing <= 0.15].index\n",
    "\n",
    "print(x_features)\n",
    "print(len(x_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the missing numeric values with respective column mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_x_features = [feat for feat in x_features if train_types[feat] == float]\n",
    "\n",
    "print(numeric_x_features)\n",
    "print(len(numeric_x_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[numeric_x_features] = x_train[numeric_x_features].fillna(\n",
    "    x_train[numeric_x_features].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_data(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now remove the categorical features that have more than 400 categories in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_x_features = [feat for feat in x_features if train_types[feat] != float]\n",
    "\n",
    "print(categorical_x_features)\n",
    "print(len(categorical_x_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_levels = x_train[categorical_x_features].apply(lambda col: len(col.cat.categories))\n",
    "\n",
    "categorical_x_features_filtered = categorical_levels[categorical_levels <= 400].index.tolist()\n",
    "print(categorical_x_features_filtered)\n",
    "print(len(categorical_x_features_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features_filtered = numeric_x_features + categorical_x_features_filtered\n",
    "print(x_features_filtered)\n",
    "print(len(x_features_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[x_features_filtered]\n",
    "x_train = pd.get_dummies(x_train, dtype=bool)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = xgboost.DMatrix(data=pd.get_dummies(x_train, dtype=bool), label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(\n",
    "    n_jobs=8,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=3000,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
